---
permalink: /
title: "Sean(HaoJin) Wang"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I am a senior undergraduate at [Tongji University](https://en.tongji.edu.cn/) in Shanghai, China. I major in computer science and technology at School of Electronic and Information Engineering and will be graduating in July, 2025. I will be working as a Visiting Scholar at the [University of Waterloo](https://uwaterloo.ca/) in the David R. Cheriton School of Computer Science, Faculty of Mathematics, term from 15 September 2024 to 31 December 2024, on the recommendation of Professor [Freda Shi](https://home.ttic.edu/~freda/). Currently, I am focusing on my work in analyzing the probability distributions defined by language models. I am also working as a remote intern student at [Rice University](https://www.rice.edu/), under the guidance of Professor [Hanjie Chen](https://hanjiechen.github.io/), working on a project about the estimation of uncertainty of natural language generation of LLMs.

I am actively searching for internships, master programs and PhD opportunities which can allow me to take my research into next level.

Links: [CV](../assets/Sean.pdf)


Research Overview
======
My research interests are in Natural Language Processing, especially in works of aligning LLMs with human values, building Helpful, Harmless and Honest Large Language models.

My **research vision** is to build a system that can balance both helpfulness and harmlessness. And to build a system like this, I want to dive into the field of building a trustworthy and explainable AI system.

Updates
======
**July 2024**: I will be joining Prof [Hanjie Chen](https://hanjiechen.github.io/) at [Rice University](https://www.rice.edu/). We are currently actively discussing the details of the estimation of uncertainty of the generated language from LLMs. It will be difficult job, but I want to treat it as a long term project for my future master career or PhD career. The works of the estimation of uncertainty currently limited in classification tasks, and applying it to natural language generation can take the current alignment works into next level.

**May 2024**: I will be joining research work with Prof [Freda Shi](https://home.ttic.edu/~freda/) at [University of Waterloo](https://uwaterloo.ca/). Me and Freda are working on a project to analyze the difficulty of triggering different desirable distributions using prefix tuning. And from my perspective, the result of work is **promising** so far, and later it can be applied to other LLM field, including testing the certainty of the model in a setting of NLG tasks.

**Jan 2024**: I am studying as an exchanger at [National University of Singapore](https://nus.edu.sg/), and I will be taking 3 courses here including [CS2108: Introduction to Media Computing](https://nusmods.com/courses/CS2108/introduction-to-media-computing), [CS3245: Information Retrieval](https://nusmods.com/courses/CS3245/information-retrieval) and [IS3107: Data Engineering](https://nusmods.com/courses/IS3107/data-engineering).

Publications
======
Expecting to come in October.